# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1 - Task 1
library(magrittr)
library(tseries)
# set seed 
set.seed(17076749)
# set address
address <- "https://www.metoffice.gov.uk/pub/data/weather/uk/climate/datasets/"
# set features
features <- c("Tmax", "Tmean", "Tmin")
# create a list of districts
districts <- c("Northern_Ireland",
                  "Scotland_N",
                  "Scotland_E",
                  "Scotland_W",
                  "England_E_and_NE",
                  "England_NW_and_N_Wales",
                  "Midlands",
                  "East_Anglia",
                  "England_SW_and_S_Wales",
                  "England_SE_and_Central_S")
# how many rows
nrow <- 2020-1884+1
# Time Series function
create.ts <- function(feature, district){ # pass 2 parameters 
  c(address, feature, "/date/", district, ".txt") %>%  # set the url with several features adding 2 text fields
    paste(collapse = "") %>%  # collapse the set urls above with no space
    read.table(skip = 5, header = TRUE, nrows = nrow) %>%  # read the table, skip 5 rows, add first col as headers and nrows is 2020-1884+1
    subset(select = 2:13) %>%  # only select Jan - Dec
    t() %>% # transpose matrix
    as.vector() %>% # save it as a vector 
    ts(start = c(1884, 1),frequency = 12) # create a time-series object
}
# test the function
create.ts("Tmax", "Northern_Ireland")
# function to get all districts & features 
readFeatures <- function(feature){
  lapply(districts, create.ts, feature = feature) %>% 
    set_names(districts)
}
# get them all together.
Data <- lapply(features, readFeatures) %>% set_names(features)

# select the Tmax from Northern_Ireland
Data$Tmax$Northern_Ireland

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 2 - Task 2
# find max temp

# find the max value's index
maxIndex <- Data$Tmax %>% 
  unlist() %>% 
  as.vector() %>% 
  which.max() 

# find sub position
subIndex <- round((maxIndex/16440)*10) # 8 - This could be district

# find max value
# maxVal <- DTmUn %>% which.max()

# find year
# maxYear <- floor(time(DTmUn))[which.max(DTmUn)]

# month
# maxMonth <- month.abb[(time(Data$Tmax)[which.max(Data$Tmax)] %>% 1)*12+1]

# calculate regions
# maxRegions <- names(Data$Tmax)

# GETS MONTH
unlistedTMAX <- Data$Tmax %>% unlist()
myMm <- month.abb[(time(unlistedTMAX)[which.min(unlistedTMAX)] %% 1)*12+1]
# plot(Data$Tmax$Northern_Ireland, type = 'l')

# get max temp of Tmax
sapply(Data$Tmax, which.max)

# data_min_value_time <- time(Data)[which.min(Data)]

# unlist tMAX
tmax_unl <- Data$Tmax %>% 
  unlist() %>% 
  as.vector()

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3 - Task 3
# EDA

# find max value
colMax <- function(data) sapply(data, max, na.rm = TRUE)
colMax(Data$Tmax) %>% which.max()
# East_Anglia has the highest temp within the Tmax series.
colMax(Data$Tmean) %>% which.max()
# East_Anglia has the highest temp within the Tmean series.
colMax(Data$Tmin) %>% which.max()
# England_SE_and_Central_S has the highest temp within Tmin.

# find lowest value
colMin <- function(data) sapply(data, min, na.rm = TRUE)
colMin(Data$Tmax) %>% which.min()
# Midlands has the lowest temp within the Tmax series.
colMin(Data$Tmean) %>% which.min()
# Scotland_E has the lowest temp within the Tmean series.
colMin(Data$Tmin) %>% which.min()
# Scotland_E has the lowest temp within the Tmin series

colRange <- function(data) sapply(data, range, na.rm = TRUE)
colRange(Data$Tmax)

colRange(Data$Tmean)

colRange(Data$Tmin)


# The above can also be done on the full dataset.
maxTemps <- sapply(Data, colMax)
# print
maxTemps
minTemps <- sapply(Data, colMin)
# print
minTemps
totRange <- sapply(Data, colRange)
# print
totRange

colAvg <- function(data) sapply(data, mean)
sapply(Data, colAvg)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 4 - Task 4 – Trend and Seasonality 
# 4.0 - Subset
# For each district, consider the 3 time series: max, mean, min.
# Subset each of the 30 time series until December 2019.

data <- data.frame(title1 = Data$Tmax$Northern_Ireland,
                   title2 = Data$Tmax$Scotland_N)

matCon <- function(data){
  data %>% 
    t() %>% 
    as.vector()
}
testTS <- lapply(Data, matCon)
is.vector(testTS)

# first convert all ts data to matrix
slice.ts <- function(timeseries){
  data %>% # get the timeseries data
    window(start = c(1884,12), 
         end = c(2019,12), 
         frequency = 12
         ) # and cut off everything > 2019
}
# doesn't work
slice.ts(testTS)


# sliced window on 1 dataset
slicedWindow <- 
  Data$Tmax$England_NW_and_N_Wales %>% 
  window(start = c(1884,12), 
         end = c(2019,12), 
         frequency = 12,
         extend = FALSE)
# 
slicedWindow
# 4.1 - Estimate Trend
# Estimate the trend of each time series using linear, quadratic and cubic 
# regression. Compare your results and use appropriate plots and/or tables 
# to confirm your observations.

# create time vector
time <- 1:length(slicedWindow)
time <- (time - min(time))/(max(time) - 1)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# linear trend
linear.fit <- lm(slicedWindow ~ time)
# check summary
summary(linear.fit)

# Now try to plot
# create ts plot with the data
ts.plot(slicedWindow, ylab = "Temperature")
# create linear fitted
linear.fit %>% fitted() %>% ts(start = c(1884,12), end = c(2019,12), frequency = 12) -> linear.fitted
# add linear fitted lines
lines(linear.fitted, col = "green", lwd = 2)
# add mean line
abline(mean(slicedWindow), 0, col = "blue", lwd = 2)

# check last 10 years
ts.plot(slicedWindow[1501:1621], ylab = "Temperature")
lines(linear.fitted[1501:1621], col = "green", lwd = 2)
abline(mean(slicedWindow[1501:1621]), 0, col = "blue", lwd = 2)
# temp is very slowly increasing.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# quadratic trend
# square the time
time2 <- time^2

# create quadratic fit model
quadratic.fit <- lm(slicedWindow ~ time + time2) ## HERE 2-trend-video.R in week 5
# check summary
summary(quadratic.fit)
# create linear fitted
quadratic.fit %>% fitted() %>% ts(start = c(1884,12), end = c(2019,12), frequency = 12) -> quadratic.fitted
# add linear fitted lines
lines(quadratic.fitted, col = "green", lwd = 2)
# add mean line
abline(mean(slicedWindow), 0, col = "blue", lwd = 2)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# cube time
time3 <- time^3
# create cubic fit model
cubic.fit <- lm(slicedWindow ~ time + time2 + time3)
# check summary
summary(cubic.fit)
# add cubic line
lines(time, 
      cubic.fit %>% fitted(),
      col = 'yellow',
      lwd = 3)

AIC(linear.fit) 
AIC(quadratic.fit)
AIC(cubic.fit)
# 4.2 - Select Trend
# Select a trend model for each time series using an appropriate criteria. 
# Are the models selected all the same? If not is there a pattern depending on 
# the region and/or the group (max, mean and min)?

# Linear has the lowest AIC for most ts.


# 4.3 - Estimate Seasonality
# After removing the trend using the model selected in the previous step, 
# use the output to estimate the seasonality of each time series employing averaging and sine-cosine models. 
# Compare your results and use appropriate plots and/or tables to confirm your observations.

# start with 1 dataset and remove the trend
sliced.window.notrend <- 
  (slicedWindow - fitted(linear.fit))
# get seasonal means
tapply(sliced.window.notrend, cycle(sliced.window.notrend), mean)
# create months variable as factor
months <- sliced.window.notrend %>% cycle() %>% as.factor()
# seasonal means
sliced.seas <- lm(sliced.window.notrend ~ months - 1)
# check summary for seasonal means coefficients
summary(sliced.seas)

# evaluate harmonic seasonality
# create an empty matrix
SIN <- COS <-  matrix(nrow = length(time), ncol = 6)# 6 = freq/2

for(i in 1:6){
  SIN[,i] <- sin(2*pi*i*time)
  COS[,i] <- cos(2*pi*i*time)
}

# model all season harmonic
# model notrend against all values with -1
slice.har1 <- lm(sliced.window.notrend ~ . -1 ,
                data.frame(SIN = SIN[,1], COS = COS[,1]))
# check summary
summary(slice.har1)
# create 2
slice.har2 <- lm(sliced.window.notrend ~ . -1 ,
                data.frame(SIN = SIN[,1:2], COS = COS[,1]))
# check summary
summary(slice.har2)
slice.final <- lm(slicedWindow ~ .,
                 data.frame(TIME = poly(time, degree = 1, raw = T),
                            SIN = SIN[,1:2], 
                            COS = COS[,1]))
# check summary
summary(slice.final)

plot(slicedWindow,
     main = 'AVG TEMP NW England & N Wales',
     xlab = 'Year',
     ylab = 'AVG TEMP',
     type = 'l')
lines(time, 
      fitted(slice.har2),
      lwd = 3,
      type = 'l',
      col = 'blue')

# function for seasonality
seasonal.har <- function(order){
  assign(paste(c("seasonal.har",order), collapse = ""),
         lm(sliced.window.notrend ~ . - 1,
            data.frame(SIN = SIN[,1:order], COS = COS[,1:order])))
  
  plot(sliced.window.notrend,
       main = paste("Avg Temp without trend and harmonic", order),
       lwd = 2,
       type = "l")
  
  lines(time,
        fitted(get(paste(c("seasonal.har",order), collapse = ""))),
        lwd = 3,
        col = 'green',
        lty = 1)
  
  print(summary(get(paste(c("seasonal.har",order), collapse = ""))))
  
  return(get(paste(c("seasonal.har",order), collapse = "")))
}

seas.har1 <- seasonal.har(1)
seas.har1 <- seasonal.har(2)
seas.har1 <- seasonal.har(3)



# 4.4 - Select Seasonality
# Select a seasonal model for each time series using an appropriate criteria. 
# Are the models selected all the same? If not is there a pattern depending on the region and/or the group (max, min and mean)?

# 4.5 - Estimate Seasonality
# Estimate a combined model for trend and seasonality using the results of the previous steps.
# Call this model “final”.

# 4.6 - Estimate Seasonality
# Estimate trend and seasonality using a combined quadratic and sin-cosine (of order 2) models.
# Call this model “test”






# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 5 - Task 5

# functions for all the models
# get the AIC reading for each one to see which is best.

# do for one, test it if works, create a function

# apply apply apply
# glimse at the graphs but only keep the ones which we use in report
# create a selection of each models.

# for tmax x was better
# x = linear, cubic, quadratic was better

# might have to nest 3 lapplies for each things?!

# problem could be seasionalities with p values (<0.01)

# num to month
numyear2monthyear <- function(x){   
  c(trunc(x),                   # entire part = year
    round((x-floor(x))*12 + 1)) # decimal part * 12 + 1 (Jan=0) = Month
}

# try test function on Data$Tmax
numyear2monthyear(Data$Tmax$Northern_Ireland)
numyear2monthyear(tmax_unl)

# try it with lapply
lapply(Data$Tmax, numyear2monthyear)

# yeet
extrema_dates <- function(ts){
  ts_min_date <- numyear2monthyear(time(ts)[which.min(ts)])
  ts_max_date <- numyear2monthyear(time(ts)[which.max(ts)])
  list(min=min(ts),
       min_year=ts_min_date[1],
       min_month=ts_min_date[2],
       max=max(ts),
       max_year=ts_max_date[1],
       max_month=ts_max_date[2])
}

extrema_dates(Data$Tmax$Northern_Ireland)
extrema_dates(tmax_unl)
# try to use the 2 above functions
sapply(Data$Tmax, extrema_dates)


#which.max(Data$Tmax)

numyear2monthyear(time(data)[which.max(data)])

numyear2monthyear(time(data)[which.min(data)])