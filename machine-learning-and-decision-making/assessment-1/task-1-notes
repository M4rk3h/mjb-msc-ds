TASK 1

Hi there, my name is Mark and this is my video walkthrough of my Machine Learning coursework.
This coursework was to use a dataset from the Open University and try to predict which students are more likely to dropout or fail on a course.

Task A - Task ask is going to be exploring the data and getting suitable datasets for the next step which is machine learning.

The first thing I did was to put all of the modules i've eventually used throughout the coursework, I put them up the top to ensure I wasn't constantly importing them, when I needed them.

I then imported all of the datasets at the front so we can easily get them and manipulate them throughout the cw.

PART 1.1 is going to be using EDA techniques on the first dataset - Assessment.
I started by looking at the head to see what is within the dataset, this shows the colums within the dataset with a small description of what they represent, Next I looked at the tail to see the last 5 entries within the dataste.

After this, i've descided to use the info command which gives some information about the datasets, this shows the columns, NA values and the data types.

Whilst this is great for finding nulls and seeing which columns would need to be converted for machine learning models, it would be interesting to see the length of unique values. I did this with a loop which looked at the columns and the unique values.

I also modified this loop to show the length of unique values again, but to also print the actual values. Which was pretty good, but print a lot of values like these.

The final step was to look at the spread of the dataset, this was done with the describe command which shows the count, mean and some other things which could be useful. I also managed to include the objects which doesn't really show anything of value.

To conclude for the first dataset, there doesn't seem to be much I can do with this dataset as is but this could be more useful if joined with other datasets.

PART 1.2 - Course
For this dataset, I pretty much followed the same steps as part 1.1 with the eda, although with this dataset I found 2 out of the 3 columns were the same as part 1.1. So not much of note with this dataset.

PART 1.3 - Student Assessment
This dataset looks to have some useful information from first look, showing the students score for certain assessments. For this I thought why not look at the students who got fails on their scores (<40) and see the distribution of fails. There were 7751 students who failed within the dataset, with the average score being 23.  On the graph there are a lot of 0 values, but this is due to the NA's being set to 0.

Let's now do this for students who passed, there were a lot more students who passed with the average being 78 which is pretty good. This can be shown on a graph which shows a lot of 100's within the dataset too. This could either be a mistake within the dataset, or they're all very good students.

PART 1.4 - Student Info
The student info table seemed to have a lot of interesting values, a lot of these were categorical. Due to there being so many categorical values, I had a few ideas *LIST THEM*

These will be explored further in the next section before converting all categorical values which will make using them easier in the future.

I started by cleaning, grouping and counting all of the values for multiple categories.
Starting with AgeBand, does the age band affect the final results. Here we can see the percentage per group for each final band. 

This section was one of the longest within the EDA section.

PART 1.8 - NEW FEATURES
After going through EDA, there were multiple things which stood out to me when creating new features, for this part tho i wanted to cut it down to the main goal of this coursework. Finding students who withdrew or failed a course.

To start with I thought about what data I needed to merge, for this I wanted to get the students score, the students final results, all the categorical values along with the students clicks (student interaction).

From this table we can get a quick look at the new combined table called student course info, with multiple columns which could be very useful for the next couple of tasks.

First lets plot this dataset and see how the avg clicks affect the final results. The plot shows there is a lot of interaction for pass (as loads of students got a pass) with a few outliers peaking up the top with a lot of interaction. The student interaction looks also similar with Distinctions, with less outliers.

The next step would be the Data Cleaning, this section will look at removing the text categories and converting them into int values (0,1,2,3) which can easily be read by the machine learning models.

I started with the final results, counted each entried for each result and dropped na's. After getting rid of any missing values, I created a copy of the dataframe so I could start using the Label Encoder from SciKit Learn. 

This big mess of code is simply getting the column we wanted to encode, and using the label encoder to fit transform the column. This converts the categorical value to a number or int value as mentioned above. This was done for every categorical value, but created a work around for the imd_band (% of depravity) which was coded with cat.codes (code the categories) from the pandas package.

