{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read housing data\n",
    "housing = pd.read_csv (r'data/house.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_median_age  total_rooms  total_bedrooms  population  households  \\\n",
       "0                41.0        880.0           129.0       322.0       126.0   \n",
       "1                21.0       7099.0          1106.0      2401.0      1138.0   \n",
       "2                52.0       1467.0           190.0       496.0       177.0   \n",
       "3                52.0       1274.0           235.0       558.0       219.0   \n",
       "4                52.0       1627.0           280.0       565.0       259.0   \n",
       "\n",
       "   median_income  median_house_value ocean_proximity  \n",
       "0         8.3252            452600.0        NEAR BAY  \n",
       "1         8.3014            358500.0        NEAR BAY  \n",
       "2         7.2574            352100.0        NEAR BAY  \n",
       "3         5.6431            341300.0        NEAR BAY  \n",
       "4         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a copy of following features\n",
    "housing_df = housing[['housing_median_age', 'total_rooms',\n",
    "        'total_bedrooms', 'population', 'households', 'median_income',\n",
    "        'median_house_value','ocean_proximity']].copy()\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> The usual missing value imputation routine please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    20640\n",
       "Name: total_bedrooms, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "housing_df['total_bedrooms'].isna().value_counts()\n",
    "# fill misisng values with median\n",
    "median_tb = housing['total_bedrooms'].median()\n",
    "# fill the na's with median\n",
    "housing_df['total_bedrooms'].fillna(median_tb,inplace = True)\n",
    "housing_df['total_bedrooms'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue> Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> instead of mapping the categorical variable<br>\n",
    "    use label encoder from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import preprocessing from sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable called lab_enc which is labelEncoder\n",
    "lab_enc = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique labels we want to change\n",
    "lab_enc.fit(housing_df['ocean_proximity'].unique())\n",
    "# check the unique values\n",
    "housing_df['ocean_proximity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique values to the ones above\n",
    "list(lab_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NEAR BAY\n",
       "1    NEAR BAY\n",
       "2    NEAR BAY\n",
       "3    NEAR BAY\n",
       "4    NEAR BAY\n",
       "Name: ocean_proximity, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df['ocean_proximity'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20635    INLAND\n",
       "20636    INLAND\n",
       "20637    INLAND\n",
       "20638    INLAND\n",
       "20639    INLAND\n",
       "Name: ocean_proximity, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df['ocean_proximity'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now transform the data with the labelEncoder\n",
    "housing_df['ocean_proximity'] = lab_enc.transform(housing_df['ocean_proximity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    3\n",
       "3    3\n",
       "4    3\n",
       "Name: ocean_proximity, dtype: int32"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check head again\n",
    "housing_df['ocean_proximity'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20635    1\n",
       "20636    1\n",
       "20637    1\n",
       "20638    1\n",
       "20639    1\n",
       "Name: ocean_proximity, dtype: int32"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check tail again\n",
    "housing_df['ocean_proximity'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> Now the usual scaling routine please "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using StandardScaler as ss, scale the data\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "temp = housing_df[['housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income',\n",
    "       'median_house_value']].copy()\n",
    "temp = ss().fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982143</td>\n",
       "      <td>-0.804819</td>\n",
       "      <td>-0.972476</td>\n",
       "      <td>-0.974429</td>\n",
       "      <td>-0.977033</td>\n",
       "      <td>2.344766</td>\n",
       "      <td>2.129631</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.607019</td>\n",
       "      <td>2.045890</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>1.669961</td>\n",
       "      <td>2.332238</td>\n",
       "      <td>1.314156</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.856182</td>\n",
       "      <td>-0.535746</td>\n",
       "      <td>-0.827024</td>\n",
       "      <td>-0.820777</td>\n",
       "      <td>-0.843637</td>\n",
       "      <td>1.782699</td>\n",
       "      <td>1.258693</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.856182</td>\n",
       "      <td>-0.624215</td>\n",
       "      <td>-0.719723</td>\n",
       "      <td>-0.766028</td>\n",
       "      <td>-0.733781</td>\n",
       "      <td>0.932968</td>\n",
       "      <td>1.165100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.856182</td>\n",
       "      <td>-0.462404</td>\n",
       "      <td>-0.612423</td>\n",
       "      <td>-0.759847</td>\n",
       "      <td>-0.629157</td>\n",
       "      <td>-0.012881</td>\n",
       "      <td>1.172900</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_median_age  total_rooms  total_bedrooms  population  households  \\\n",
       "0            0.982143    -0.804819       -0.972476   -0.974429   -0.977033   \n",
       "1           -0.607019     2.045890        1.357143    0.861439    1.669961   \n",
       "2            1.856182    -0.535746       -0.827024   -0.820777   -0.843637   \n",
       "3            1.856182    -0.624215       -0.719723   -0.766028   -0.733781   \n",
       "4            1.856182    -0.462404       -0.612423   -0.759847   -0.629157   \n",
       "\n",
       "   median_income  median_house_value  ocean_proximity  \n",
       "0       2.344766            2.129631                3  \n",
       "1       2.332238            1.314156                3  \n",
       "2       1.782699            1.258693                3  \n",
       "3       0.932968            1.165100                3  \n",
       "4      -0.012881            1.172900                3  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df[['housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income',\n",
    "       'median_house_value']] = temp\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> Create the feature set<br>\n",
    "    that is: train and test splits<br>\n",
    "    <br>\n",
    "    \n",
    "<font color = purple> note: Do not create separate dataframes from predictor variables and target variables<br>\n",
    "<font color = purple> just provide the indices in train_Test_split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# set the train and test variables against *!=6\n",
    "# with test being only 6 \n",
    "x_housing_train, x_housing_test, y_housing_train, y_housing_test = train_test_split(housing_df.iloc[:, [0,1,2,3,4,5,7]]\n",
    ", housing_df.iloc[:, [6]]\n",
    ", test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12364</th>\n",
       "      <td>-1.798890</td>\n",
       "      <td>1.020937</td>\n",
       "      <td>0.913633</td>\n",
       "      <td>1.399218</td>\n",
       "      <td>0.859123</td>\n",
       "      <td>0.042178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12271</th>\n",
       "      <td>-0.607019</td>\n",
       "      <td>0.911382</td>\n",
       "      <td>0.751490</td>\n",
       "      <td>0.660986</td>\n",
       "      <td>0.817273</td>\n",
       "      <td>-0.181690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19605</th>\n",
       "      <td>0.267020</td>\n",
       "      <td>-0.774566</td>\n",
       "      <td>-0.807949</td>\n",
       "      <td>-0.707747</td>\n",
       "      <td>-0.854099</td>\n",
       "      <td>-0.998997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10600</th>\n",
       "      <td>-1.639974</td>\n",
       "      <td>-0.276757</td>\n",
       "      <td>-0.447895</td>\n",
       "      <td>-0.497580</td>\n",
       "      <td>-0.417293</td>\n",
       "      <td>1.601573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.856182</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.278598</td>\n",
       "      <td>-0.624740</td>\n",
       "      <td>-0.307438</td>\n",
       "      <td>-0.628427</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housing_median_age  total_rooms  total_bedrooms  population  \\\n",
       "12364           -1.798890     1.020937        0.913633    1.399218   \n",
       "12271           -0.607019     0.911382        0.751490    0.660986   \n",
       "19605            0.267020    -0.774566       -0.807949   -0.707747   \n",
       "10600           -1.639974    -0.276757       -0.447895   -0.497580   \n",
       "45               1.856182    -0.449111       -0.278598   -0.624740   \n",
       "\n",
       "       households  median_income  ocean_proximity  \n",
       "12364    0.859123       0.042178                1  \n",
       "12271    0.817273      -0.181690                1  \n",
       "19605   -0.854099      -0.998997                1  \n",
       "10600   -0.417293       1.601573                0  \n",
       "45      -0.307438      -0.628427                3  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_housing_train.head()\n",
    "#x_housing_test.head()\n",
    "#y_housing_train.head()\n",
    "#y_housing_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> now repeat for titanic dataset<br>\n",
    "    \n",
    "remember to use label encoder<br>\n",
    "    \n",
    "Also, try using pandas method drop to drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# read titanic data\n",
    "titanic = pd.read_csv (r'data/titanic.csv')\n",
    "# make a copy\n",
    "titanic_df = titanic.copy()\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  889 non-null    int64  \n",
      " 1   Survived     889 non-null    int64  \n",
      " 2   Pclass       889 non-null    int64  \n",
      " 3   Name         889 non-null    object \n",
      " 4   Sex          889 non-null    object \n",
      " 5   Age          712 non-null    float64\n",
      " 6   SibSp        889 non-null    int64  \n",
      " 7   Parch        889 non-null    int64  \n",
      " 8   Ticket       889 non-null    object \n",
      " 9   Fare         889 non-null    float64\n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 83.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#drop rows where Embarked has missing values\n",
    "titanic_df.dropna(subset = ['Embarked'], inplace = True)\n",
    "titanic_df['Embarked'].isna().value_counts()\n",
    "titanic_df=titanic_df.drop('Cabin', axis=1)\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  889 non-null    int64  \n",
      " 1   Survived     889 non-null    int64  \n",
      " 2   Pclass       889 non-null    int64  \n",
      " 3   Name         889 non-null    object \n",
      " 4   Sex          889 non-null    object \n",
      " 5   Age          889 non-null    float64\n",
      " 6   SibSp        889 non-null    int64  \n",
      " 7   Parch        889 non-null    int64  \n",
      " 8   Ticket       889 non-null    object \n",
      " 9   Fare         889 non-null    float64\n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 83.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# impute the age using mean\n",
    "mean_age = titanic['Age'].mean()\n",
    "# fill the na's with median\n",
    "titanic_df['Age'].fillna(median_tb,inplace = True)\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female', 'male']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use label encoder on the following features: Sex \n",
    "lab_enc.fit(titanic_df['Sex'].unique())\n",
    "list(lab_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df['Sex'] = lab_enc.transform(titanic_df['Sex'])\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'Q', 'S']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use label encoder on the following features: Sex \n",
    "lab_enc.fit(titanic_df['Embarked'].unique())\n",
    "list(lab_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markb\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\arraysetops.py:565: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [0, 1, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-e463b7066ac7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlab_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         return _encode_numpy(values, uniques, encode,\n\u001b[0m\u001b[0;32m    122\u001b[0m                              check_unknown=check_unknown)\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_check_unknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0m\u001b[0;32m     51\u001b[0m                                  % str(diff))\n\u001b[0;32m     52\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [0, 1, 2]"
     ]
    }
   ],
   "source": [
    "titanic_df['Embarked'] = lab_enc.transform(titanic_df['Embarked'])\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    0\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: Embarked, dtype: int32"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split with 0.3 as test size, 123 as randome_state\n",
    "x_titanic_train, x_titanic_test, y_titanic_train, y_titanic_test = train_test_split(titanic_df.iloc[:, [2,4,5,6,7,10]],\n",
    "\n",
    "titanic_df.iloc[:,[1]],\n",
    "\n",
    "test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color = blue>Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "G_nb = GaussianNB().fit(x_titanic_train, y_titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix, accuracy score, precision score, recall score, f1_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> Now, from the titanic dataset, pick only those predictor variables,<br>\n",
    " which can be used to train multinomial Naive Bayes<br>\n",
    " use the same train test split, make copies, add a suffix _mnb wherever appropriate<br>\n",
    " compare this mnb classifier with G_nb classifier\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue> Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> First Apply on Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> base_estimator<br>\n",
    "The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_restricted = DecisionTreeClassifier(criterion = 'entropy', random_state = 123, max_depth = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = BaggingClassifier(tree_restricted, n_estimators = 100, max_samples = 0.8, random_state = 198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bagging.fit(x_titanic_train, y_titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for our skeleton\n",
    "bagging.base_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate score for train model (slight overfit)\n",
    "bagging.score(x_titanic_train, y_titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate score for test model (slight overfit)\n",
    "bagging.score(x_titanic_test, y_titanic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> extract feature importance<br>\n",
    " then plot a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean for all features used within bagging features.\n",
    "# score is the importance\n",
    "import numpy as np\n",
    "feature_importances = np.mean([tree.feature_importances_ for tree in bagging.estimators_], axis = 0)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_series = pd.Series(feature_importances, index = ['Pclass', 'Sex','Age','Sibsp','Parch', 'Embarked'])\n",
    "feature_importances_series.plot(kind= 'barh')\n",
    "# add a title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alot of over fitting\n",
    "rf.score(x_titanic_train, y_titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alot of over fitting\n",
    "rf.score(x_titanic_test, y_titanic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> now change the values for following parameters of random forest and create model rf2<br>\n",
    " criterion to entropy<br>\n",
    " max_features to 4<br>\n",
    " n_estimators to 50<br>\n",
    " max_depth to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color = blue> Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to install\n",
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read email data set (its sms data set actually)\n",
    "sms = pd.read_csv('data/spam.csv', encoding='latin')\n",
    "sms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of garbage columns\n",
    "sms = sms.loc[:'v1','v2',]\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename appropriately \n",
    "# cat and text\n",
    "sms.columns = [1,2]\n",
    "sms.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder\n",
    "lab_enc.fit(sms['cat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['cat'] - lab_enc.transform(sms['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> extract the frequency/count of each word<br>\n",
    "   use CountVectorizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> Apply SVM<br>\n",
    " first linear kernel<br>\n",
    " then polynomial kernel<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> Now try grid search to hyper tune polynomial svm's parameter (hyperparameters)<br>\n",
    " possible parameteres include <br>\n",
    " degree<br>\n",
    " gamma<br>\n",
    " C(regularisation parameter)<br>\n",
    " kernel<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = purple> you are ready to compare NB and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
