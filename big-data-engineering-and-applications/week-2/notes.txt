# install ubuntu in vm
# update & upgrade
sudo apt update && sudo apt upgrade -y

# install openssh
sudo apt install openssh-server gedit

# check ssh status
sudo systemctl status ssh

# change hostname
sudo nano /etc/hostname

# check hostname
sudo hostname

# set hosts
sudo nano /etc/hosts

# add vm ip and bdea-master
192.168.1.166	bdea-main
192.168.1.171	bdea-worker

# install JAVA
sudo apt install openjdk-8-jdk

# add to s/bin path variables to bashrc
# JAVA
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre

# download hadoop
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz

# extract hadoop
tar -xvf hadoop-3.2.2.tar.gz

# remove archive
rm hadoop-3.2.2.tar.gz

# move and rename hadoop
sudo mv hadoop-3.2.2 /usr/local/hadoop

# add to s/bin path variables
sudo nano ~/.bashrc
# HADOOP
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
export CONF=/usr/local/hadoop/etc/hadoop

# source bash
source ~/.bashrc

# CLONE VM HERE
# reset the mac address, leave it on dhcp

# can change to static ip below
sudo nano /etc/netplan/*tab*

network:
  version: 2
  renderer: networkd
  ethernets:
    enp0s3:
      dhcp4: no
      addresses:
        - 192.168.1.171/24 # ip which you know if free
      gateway4: 192.168.1.254 # your router ip here
      nameservers:
          addresses: [8.8.8.8, 1.1.1.1]

sudo netplan apply

# generate ssh keys
ssh-keygen -t rsa

# copy master key (public) to worker
ssh-copy-id mark@bdea-master

## EDIT the 4 files
# hadoop-env.sh
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre

# core-site.xml
<configuration>
	<propterty>
		<name>fs.defaultFS</name>
		<value>hdfs://bdea-master:9000</value>
	</property>
</configuration>

# hdfs-site.xml

# after configuring the 4 files on masters, copy to worker node
scp $CONF/* mark@bdea-worker:/usr/local/hadoop/etc/hadoop

#### Mapreduce on Hadoop Cluster #### 
2.1 - Configuration on hadoop

2.1.1 Worker nodes
make sure the yarn-site.xml within the workers are setup

2.1.2 - Master node
make sure the yarn-site.xml is empty on main/master

# add more extries to bdea-master .bashrc
# HADOOP MAPPING
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_MAPPED_HOME=$HADOOP_HOME

2.1.3 - SSH Error
2.2 execute a demo mapreduce
	start hadoop on master - start-dfs.sh
	type - jps
	start yarn - start-yarn.sh
	list yarn nodes - yarn node -list
	
	test a demo map reduce task
	yarn jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar pi 16 1000

2.3 - A word count mapreduce task locally with python

2.4 - Word count mapreduce on hadoop
copy the file to the server (can paste it from terminal or download from bb)
copy the file from the server locally, to hadoop file system
	make a directory
		hadoop fs -mkdir wordcount_demo
	copy the file to a demo textfile
		hadoop fs -copyFromLocal test.txt wordcount_demo/textfile.txt
	check file has been moved
		hadoop fs -ls wordcount_demo/textfile.txt

execute the yarn job
	yarn jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.2.2.jar \
	-files /home/mark/mapper1.py,/home/mark/reducer.py \
	-mapper  '/home/mark/mapper1.py' \
	-reducer '/home/mark/reducer.py' \
	-input 'wordcount_demo/textfile.txt' \
	-output 'wordcount_demo/output_demo1'
	
There could also be errors on the read and write for the file.